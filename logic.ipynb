{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arina\\miniconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import langchain as lc\n",
    "import requests\n",
    "import pdfplumber\n",
    "\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI as oai\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json\n",
    "\n",
    "oai_key = 'sk-proj-ECVgRtY8BVwOuJXGvmumT3BlbkFJBjkKCWcGOEcL6iZmZZCJ'\n",
    "oai_client = oai(organization=\"org-23ODEGJjNISztb1VgiYQhhlL\", api_key=oai_key)\n",
    "\n",
    "gemini_key = 'AIzaSyDaRClsiV6BXWsxPoQCfHkb6dBcqhl1wl8'\n",
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job description prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "given the job description below extract the following information in a JSON format:\n",
    "\n",
    "job title:\n",
    "list of technical skills:\n",
    "seniority level (junior, mid-senior, senior, lead, vp, c-level): \n",
    "list of responsibilities:\n",
    "qualification_degree:\n",
    "qualification_preferred_degree:\n",
    "qualification_years_of_experience:\n",
    "qualification_tech_stack_experience:\n",
    "qualification_domain_knowledge:\n",
    "qualification_leading_experience:\n",
    "qualification_research_experience:\n",
    "\n",
    "\n",
    "remember your response MUST be directly parsed as a JSON object without any modifications.\n",
    "\n",
    "\n",
    "input job description:\n",
    "{job_description}                                       \n",
    "\n",
    "your response:\n",
    "                                          \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "Senior Machine Learning Engineer, ML (ML Fraud) \n",
    "\n",
    "About the job\n",
    "Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest.\n",
    "\n",
    "Affirm's Machine Learning team solves problems critical to our business model - personalizing shopping experiences, detecting fraud, optimizing interest rates, and assessing creditworthiness in real time. Our innovative products necessitate the creation of novel machine learning solutions to drive both existing and new products.\n",
    "\n",
    " What You'll Do \n",
    "\n",
    " Use Affirm's proprietary and other third party data to develop machine learning models that predict the likelihood of fraud. These models will protect victims' identities from being stolen, prevent Affirm from incurring financial loss, and increase the trust that consumers and partners have in the Affirm ecosystem \n",
    " Partner with the ML platform team to build fraud specific ML infrastructure \n",
    " Research ground breaking solutions and develop prototypes that drive the future of fraud decisioning at Affirm \n",
    " Implement and scale data pipelines, new features, and algorithms that are essential to our production models \n",
    " Collaborate with the engineering, fraud, and product teams to define requirements for new products \n",
    " Develop fraud models to maximize user conversion while minimizing fraud losses and data costs \n",
    "\n",
    " What We Look For \n",
    "\n",
    " Bachelors in a technical field with 5+ years experience building and deploying ML models. Relevant PhD can count for up to 2 YOE \n",
    " Proficiency in machine learning with experience in areas such as gradient boosting, online learning, and deep learning. Domain knowledge in fraud risk is a plus \n",
    " Strong programming skills in Python \n",
    " Experience using large scale distributed systems like Spark and Ray \n",
    " Experience using machine learning frameworks such as scikit-learn, pandas, numpy, xgboost, and pytorch \n",
    " Excellent written and oral communication skills and the capability to drive cross-functional requirements with product and engineering teams \n",
    " The ability to present technical concepts and results in an audience-appropriate way \n",
    " Persistence, patience and a strong sense of responsibility - we build the decision making that enables consumers and partners to place their trust in Affirm! \n",
    "\n",
    "Pay Grade - CAN30\n",
    "\n",
    "Employees new to Affirm or promoted into a new role, typically begin in the min to mid range.\n",
    "\n",
    "CAN Base Pay Range Per Year\n",
    "\n",
    "Min: $123,200\n",
    "\n",
    "Mid: $154,000\n",
    "\n",
    "Max: $184,800\n",
    "\n",
    "Location - Remote CAN\n",
    "\n",
    "Affirm is proud to be a remote-first company! The majority of our roles are remote and you can work almost anywhere within the country of employment. Affirmers in proximal roles have the flexibility to work remotely, but will occasionally be required to work out of their assigned Affirm office. A limited number of roles remain office-based due to the nature of their job responsibilities.\n",
    "\n",
    "Benefits\n",
    "\n",
    "We're extremely proud to offer competitive benefits that are anchored to our core value of people come first. Some key highlights of our benefits package include:\n",
    "\n",
    " Health care coverage - Affirm covers all premiums for all levels of coverage for you and your dependents \n",
    " Flexible Spending Wallets - generous stipends for spending on Technology, Food, various Lifestyle needs, and family forming expenses \n",
    " Time off - competitive vacation and holiday schedules allowing you to take time off to rest and recharge \n",
    " ESPP - An employee stock purchase plan enabling you to buy shares of Affirm at a discount \n",
    "\n",
    "We believe It's On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.\n",
    "\n",
    "[For U.S. positions that could be performed in Los Angeles or San Francisco] Pursuant to the San Francisco Fair Chance Ordinance and Los Angeles Fair Chance Initiative for Hiring Ordinance, Affirm will consider for employment qualified applicants with arrest and conviction records.\n",
    "\n",
    "By clicking Submit Application, you acknowledge that you have read the Affirm Employment Privacy Policy for applicants within the United States, the EU Employee Notice Regarding Use of Personal Data (Poland) for applicants applying from Poland, the EU Employee Notice Regarding Use of Personal Data (Spain) for applicants applying from Spain, or the Affirm U.K. Limited Employee Notice Regarding Use of Personal Data for applicants applying from the United Kingdom, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "The text of a resume will be provided and you will extract some formatted information from it.\n",
    "\n",
    "before I list the required fields please consider the following hints that might help you in extracting the information:\n",
    "\n",
    "hint1: years of experience should be calculated based on the oldest job start date and the current date.\n",
    "hint2: technical skills can be directly extracted from a list of skills or infered from previous experience and their descriptions.\n",
    "hint3: seniority level can be inferred from the job titles and years of experience, please chose one of the following: junior, mid-senior, senior, lead, vp, c-level.\n",
    "\n",
    "please remember that your response MUST be formatted as a JSON object.\n",
    "\n",
    "----------------------\n",
    "following is the list of required fields:\n",
    "\n",
    "full name:\n",
    "email:\n",
    "phone:\n",
    "location:\n",
    "latest_title:\n",
    "list_of_previous_titles:\n",
    "latest_company:\n",
    "oldest_job_start_date:\n",
    "yesrs_of_experience:\n",
    "list_of_all_technical_skills:\n",
    "seniority_level:\n",
    "has_team_leading_experience:\n",
    "has_project_leading_experience:\n",
    "has_product_leading_experience:\n",
    "has_mentoring_experience:\n",
    "has_research_experience:\n",
    "most_recent_degree:\n",
    "responsibilities_and_achievements:\n",
    "\n",
    "----------------------\n",
    "input resume:\n",
    "{resume}\n",
    "----------------------\n",
    "your response:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The text of a resume will be provided and you will extract some formatted information from it.\n",
      "\n",
      "before I list the required fields please consider the following hints that might help you in extracting the information:\n",
      "\n",
      "hint1: years of experience should be calculated based on the oldest job start date and the current date.\n",
      "hint2: technical skills can be directly extracted from a list of skills or infered from previous experience and their descriptions.\n",
      "hint3: seniority level can be inferred from the job titles and years of experience, please chose one of the following: junior, mid-senior, senior, lead, vp, c-level.\n",
      "\n",
      "please remember that your response MUST be formatted as a JSON object.\n",
      "\n",
      "----------------------\n",
      "following is the list of required fields:\n",
      "\n",
      "full name:\n",
      "email:\n",
      "phone:\n",
      "location:\n",
      "latest_title:\n",
      "list_of_previous_titles:\n",
      "latest_company:\n",
      "oldest_job_start_date:\n",
      "yesrs_of_experience:\n",
      "list_of_all_technical_skills:\n",
      "seniority_level:\n",
      "has_team_leading_experience:\n",
      "has_project_leading_experience:\n",
      "has_product_leading_experience:\n",
      "has_mentoring_experience:\n",
      "has_research_experience:\n",
      "most_recent_degree:\n",
      "responsibilities_and_achievements:\n",
      "\n",
      "----------------------\n",
      "input resume:\n",
      "\n",
      "Arian Naseh Email : a.nasehzade@gmail.com\n",
      "LinkedIn, Personal Website, Medium Mobile : +1-647-561-2559\n",
      "Summary\n",
      "A seasoned machine learning engineer with over 4 years of hands-on experience in designing, developing, and\n",
      "deploying machine learning models and data solutions. Proven expertise in predictive modeling, building large-\n",
      "scale data processing pipelines, and risk analysis primarily in the financial and advertising sectors. Adept at\n",
      "collaborating with cross-functional teams and offering support to junior members. Known for driving projects\n",
      "from conception to completion and consistently seeking opportunities to innovate. Demonstrated ability to adapt\n",
      "to new challenges, integrate emerging technologies, and work effectively in diverse team environments.\n",
      "Technical Toolkit\n",
      "• Programming & Scripting: Python, Java, Shell Scripting\n",
      "• Machine Learning & Data Analysis: TensorFlow, Keras, Scikit-Learn, PyTorch, XGBoost, CatBoost,\n",
      "LightGBM, StatsForecast\n",
      "• LLMs & GenAi: OpenAI API, LangChain, DSPy, ChromaDB, AzureAI Search\n",
      "• Cloud Services, Data Management & Processing: Microsoft Azure ML, Google Cloud Platform,\n",
      "Airflow, SnowFlake, Microsoft SQL Server, Google BigQuery\n",
      "• Visualization & Reporting: Matplotlib, Seaborn, Streamlit, Power BI, Tableau, Plotly\n",
      "• Others: Git, Latex, Open AI Gym, Stable Baselines, PyCaret, MATLAB, Weka\n",
      "Experience\n",
      "North Bridge Financial Toronto, ON\n",
      "•\n",
      "Machine Learning Engineer May 2022 - Present\n",
      "◦ Auto Insurance Risk Management:\n",
      "- Solely led the overhaul of the Risk Sharing Pool (RSP) system, resulting in savings of over $1M annually.\n",
      "- Designed and implemented XGBoost models to assess vehicle loss probabilities and expected loss values.\n",
      "- Developed and automated a large-scale data processing pipeline on Microsoft Azure ML, ensuring weekly updates.\n",
      "- Collaborated with stakeholders to provide transparency and insights, leading to strategic decision-making.\n",
      "◦ Smart Staffing:\n",
      "- Predicted regional workloads, enabling the business team to better prepare and move their staff as needed. Gener-\n",
      "ated an estimated value of $500K annually.\n",
      "-Developedandtrainedmodelson32distincttimeseriestargets,utilizingCatBoost,intermittenttimeseriesmodels\n",
      "(TSB, IMAPA, ADIDA, Croston Classic), and AutoArima, optimizing based on cumulative forecasting error.\n",
      "-Developedasystemtoanalyzeandpredictpotentialworkloads,enablingbetterresourceallocationandunderstand-\n",
      "ing of historical versus potential demand.\n",
      "◦ GenAI Initiatives:\n",
      "Claims Auditing Automation PoC:\n",
      "- Engineered a RAG-based proof of concept that automated key auditing tasks.\n",
      "- Utilized Azure AI Search, ChromaDB, Langchain, Azure OpenAI deployments (gpt & embedding models), FAISS.\n",
      "- Provided crucial ROI insights that influenced the strategic decision to halt full-scale deployment due to cost\n",
      "considerations.\n",
      "Automated Claim Creation Initiative:\n",
      "- Leading the development of a system that automates claim creation from emails received from multiple entities.\n",
      "- Developed a PoC that automates the processing of First Notice of Loss emails from a source that accounts for 25%\n",
      "of all auto insurance claims.\n",
      "Docma Toronto, ON\n",
      "•\n",
      "Consulting Data Scientist - Part Time Contract June 2023 - January 2024\n",
      "◦ Endpoint Development:\n",
      "- Developed endpoints to compute various metrics for targeted advertisement campaigns.\n",
      "- Designed and implemented various test scripts to ensure the quality of existing and developing endpoints.\n",
      "- Debugged existing code base, and proposed a repository structure which better suited a data product.\n",
      "◦ Audience Profiling Endpoint:\n",
      "- Significantly enhanced execution time for the audience profiling algorithm, while maintaining the quality of the\n",
      "estimations.\n",
      "- Designed experiments to test the accuracy of the profiling for different segments of population.\n",
      "TicTie Labs Toronto, ON\n",
      "•\n",
      "Data Scientist June 2021 - May 2022\n",
      "◦ Yield prediction:\n",
      "- Implemented machine learning algorithms to develop a predictive app that estimates the yield of products under\n",
      "different environmental conditions to help indoor farm operators meet their customers’ needs.\n",
      "◦ Environment Monitoring Dashboards:\n",
      "- Developed data-rich reports using Python, SQL, and Microsoft PowerBi to help the farms’ operators monitor\n",
      "environmental parameters such as temperature, and notify them if the parameters were out of acceptable range.\n",
      "◦ Android App PoC: - Created an Android app to help farmers capture operational data without disrupting their\n",
      "workflow.\n",
      "York University Toronto, ON\n",
      "•\n",
      "Research Assistant September 2019 - May 2021\n",
      "◦ Machine Learning Research:\n",
      "- Conducted research on machine learning algorithms, especially Reinforcement Learning, and its application in IoT.\n",
      "-AppliedDeepReinforcementLearningmethodsthecachingprobleminIoTnetworks. Improvedenergyconsumption\n",
      "by more than 30% in comparison to conventional methods.\n",
      "- Developed problem-solving skills and excellent communication skills during years of collaborative research.\n",
      "Education\n",
      "York University Toronto, ON\n",
      "•\n",
      "M.Sc. Computer Engineering; GPA: A September 2019 - May 2021\n",
      "◦ Key Courses:\n",
      "MachineLearningTheory,ProbabilisticModelsandMachineLearning,DataAnalytics&Visualization,DataMining\n",
      "Amirkabir University of Technology Tehran, Iran\n",
      "•\n",
      "M.Sc. Digital Systems - Electronics; GPA: A September 2016 - May 2019\n",
      "◦ Key Courses: Statistical Machine Learning, Artificial Intelligence (Bio-Inspired AI), Computer Vision, Internet of\n",
      "Things, Digital Signal Processing (DSP), Advanced Computer Networks\n",
      "University of Guilan Rasht, Iran\n",
      "•\n",
      "B.Sc. Electrical Engineering - Electronics; GPA: B+ September 2011 - April 2016\n",
      "◦ Key Courses: Statistics, Algebra, Signal and System Analysis, Mathematics in Engineering\n",
      "Publication\n",
      "• A. Nasehzadeh and P. Wang, “A deep reinforcement learning-based caching strategy for internet of things,”\n",
      "in 2020 IEEE/CIC International Conference on Communications in China (ICCC), pp. 969–974, 2020.\n",
      "• H. Wu, A. Nasehzadeh and P. Wang, ”A Deep Reinforcement Learning-Based Caching strategy for IoT\n",
      "Networks With Transient Data,” in IEEE Transactions on Vehicular Technology, vol. 71, no. 12, pp. 13310-\n",
      "13319, Dec. 2022, doi: .1109/TVT.2022.3199677.\n",
      "Certifications\n",
      "• Structuring Machine Learning Projects - Coursera\n",
      "• Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization - Coursera\n",
      "• Google Cloud Platform: Create and Manage Cloud Resources - Google\n",
      "----------------------\n",
      "your response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_resume = \"\"\n",
    "with pdfplumber.open(\"Arian_Naseh_Resume.pdf\") as f:\n",
    "    resume=\"\"\n",
    "    if len(f.pages)<2:\n",
    "        resume = f.pages[0].extract_text()\n",
    "    else:\n",
    "        for i in range(2):\n",
    "            resume += \"\\n\" + f.pages[i].extract_text()\n",
    "    current_resume = resume_prompt.format(resume=resume)\n",
    "print(current_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_template = PromptTemplate.from_template(\n",
    "\"\"\" \n",
    "You are one of the best recruiters in the world, and you should make a decision on whether an applicant should be considered any further or they are not a good fith for the job. \n",
    "You are provided with 2 JSON objects, one is the extracted information from the job description and the other is the extracted information from the resume.\n",
    "\n",
    "your response MUST have 3 parts, a score, a label and some notes.\n",
    "the score must be between 1-5 based on how well they match the job description. 5 is the best match, 1 is the worst.\n",
    "label must be one of the follwings: \"strongly recommended! a super star\", \"recommended for technical interview\", \"recommended for a screening call\", \"no match - under qualified\", \"no match - over qualified\"\n",
    "in the notes section, you compare the responsibilities of and required skills of the job description against the ones from the resume and provide some insights on why you chose the label and score. \n",
    "\n",
    "hint: if required degree is Bachlor, but PhD is preferred degree, and the applicant has a M.Sc degree, it means the applicant has better than the required qualifications, and it is a bonous\n",
    "-----\n",
    "required fields in the output are:\n",
    "\n",
    "score:\n",
    "label:\n",
    "notes:\n",
    "\n",
    "-----\n",
    "job description info:\n",
    "{jd_json}\n",
    "\n",
    "-----\n",
    "resume info:\n",
    "{resume_json}\n",
    "\n",
    "-----\n",
    "your response:\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job description extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"job title\": \"Senior Machine Learning Engineer, ML (ML Fraud)\",\n",
      "    \"list of technical skills\": [\n",
      "        \"Proficiency in machine learning with experience in areas such as gradient boosting, online learning, and deep learning\",\n",
      "        \"Strong programming skills in Python\",\n",
      "        \"Experience using large scale distributed systems like Spark and Ray\",\n",
      "        \"Experience using machine learning frameworks such as scikit-learn, pandas, numpy, xgboost, and pytorch\"\n",
      "    ],\n",
      "    \"seniority level\": \"senior\",\n",
      "    \"list of responsibilities\": [\n",
      "        \"Develop machine learning models that predict the likelihood of fraud\",\n",
      "        \"Partner with the ML platform team to build fraud specific ML infrastructure\",\n",
      "        \"Research ground breaking solutions and develop prototypes for fraud decisioning\",\n",
      "        \"Implement and scale data pipelines, new features, and algorithms for production models\",\n",
      "        \"Collaborate with engineering, fraud, and product teams to define requirements for new products\",\n",
      "        \"Develop fraud models to maximize user conversion while minimizing fraud losses and data costs\"\n",
      "    ],\n",
      "    \"qualification_degree\": \"Bachelors in a technical field\",\n",
      "    \"qualification_preferred_degree\": \"Relevant PhD\",\n",
      "    \"qualification_years_of_experience\": \"5+ years building and deploying ML models\",\n",
      "    \"qualification_tech_stack_experience\": \"Experience in machine learning with specific technical skills\",\n",
      "    \"qualification_domain_knowledge\": \"Domain knowledge in fraud risk is a plus\",\n",
      "    \"qualification_leading_experience\": null,\n",
      "    \"qualification_research_experience\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "jd_response = get_response(job_prompt.format(job_description=job_description))\n",
    "print(jd_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_resume = \"\"\n",
    "with pdfplumber.open(\"Arian_Naseh_Resume.pdf\") as f:\n",
    "    resume=\"\"\n",
    "    if len(f.pages)<2:\n",
    "        resume = f.pages[0].extract_text()\n",
    "    else:\n",
    "        for i in range(2):\n",
    "            resume += \"\\n\" + f.pages[i].extract_text()\n",
    "    current_resume = resume_prompt.format(resume=resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"full name\": \"Arian Naseh\",\n",
      "    \"email\": \"a.nasehzade@gmail.com\",\n",
      "    \"phone\": \"+1-647-561-2559\",\n",
      "    \"location\": \"Toronto, ON\",\n",
      "    \"latest_title\": \"Machine Learning Engineer\",\n",
      "    \"list_of_previous_titles\": [\n",
      "        \"Consulting Data Scientist - Part Time Contract\",\n",
      "        \"Data Scientist\",\n",
      "        \"Research Assistant\"\n",
      "    ],\n",
      "    \"latest_company\": \"North Bridge Financial\",\n",
      "    \"oldest_job_start_date\": \"September 2019\",\n",
      "    \"years_of_experience\": 3,\n",
      "    \"list_of_all_technical_skills\": [\n",
      "        \"Python\",\n",
      "        \"Java\",\n",
      "        \"Shell Scripting\",\n",
      "        \"TensorFlow\",\n",
      "        \"Keras\",\n",
      "        \"Scikit-Learn\",\n",
      "        \"PyTorch\",\n",
      "        \"XGBoost\",\n",
      "        \"CatBoost\",\n",
      "        \"LightGBM\",\n",
      "        \"StatsForecast\",\n",
      "        \"Microsoft Azure ML\",\n",
      "        \"Google Cloud Platform\",\n",
      "        \"Airflow\",\n",
      "        \"SnowFlake\",\n",
      "        \"Microsoft SQL Server\",\n",
      "        \"Google BigQuery\",\n",
      "        \"Matplotlib\",\n",
      "        \"Seaborn\",\n",
      "        \"Streamlit\",\n",
      "        \"Power BI\",\n",
      "        \"Tableau\",\n",
      "        \"Plotly\",\n",
      "        \"Git\",\n",
      "        \"Latex\",\n",
      "        \"Open AI Gym\",\n",
      "        \"Stable Baselines\",\n",
      "        \"PyCaret\",\n",
      "        \"MATLAB\",\n",
      "        \"Weka\"\n",
      "    ],\n",
      "    \"seniority_level\": \"mid-senior\",\n",
      "    \"has_team_leading_experience\": true,\n",
      "    \"has_project_leading_experience\": true,\n",
      "    \"has_product_leading_experience\": false,\n",
      "    \"has_mentoring_experience\": true,\n",
      "    \"has_research_experience\": true,\n",
      "    \"most_recent_degree\": \"M.Sc. Computer Engineering\",\n",
      "    \"responsibilities_and_achievements\": \"Led the overhaul of the Risk Sharing Pool system resulting in significant savings, developed and automated data processing pipelines, collaborated with stakeholders for strategic decision-making, predicted regional workloads, enhanced execution time for audience profiling algorithm, implemented machine learning algorithms for yield prediction, developed data-rich reports for environment monitoring, conducted research on machine learning algorithms with a focus on Reinforcement Learning, improved energy consumption in IoT networks, published research papers, completed relevant certifications.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resume_response = get_response(current_resume)\n",
    "print(resume_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_prompt = comparison_template.format(\n",
    "    jd_json=jd_response.choices[0].message.content, \n",
    "    resume_json=resume_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"score\": 3,\n",
      "    \"label\": \"recommended for a screening call\",\n",
      "    \"notes\": \"The applicant, Arian Naseh, has a M.Sc. in Computer Engineering, which is higher than the required Bachelor's degree. They have 3 years of experience, which is less than the required 5+ years. However, they have a strong background in machine learning with experience in various technical skills such as Python, Scikit-Learn, PyTorch, XGBoost, and more. While they may not meet all the qualifications, they show potential and could be a good fit for a screening call to further assess their skills and experience.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "comparison_response = get_response(comparison_prompt)\n",
    "print(comparison_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "chat = gemini_flash.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gemini_flash.generate_content(\"what is the required skill sets for a midsenior ML engineer? (do not format your response as Markdown, I want to directly print out the response.) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gemini_flash.generate_content(job_prompt.format(job_description=job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job title': 'Senior Machine Learning Engineer, ML (ML Fraud)',\n",
       " 'list of technical skills': ['machine learning',\n",
       "  'gradient boosting',\n",
       "  'online learning',\n",
       "  'deep learning',\n",
       "  'fraud risk',\n",
       "  'Python',\n",
       "  'Spark',\n",
       "  'Ray',\n",
       "  'scikit-learn',\n",
       "  'pandas',\n",
       "  'numpy',\n",
       "  'xgboost',\n",
       "  'pytorch',\n",
       "  'data pipelines',\n",
       "  'algorithms'],\n",
       " 'seniority level': 'senior',\n",
       " 'list of responsibilities': [\"Use Affirm's proprietary and other third party data to develop machine learning models that predict the likelihood of fraud.\",\n",
       "  \"These models will protect victims' identities from being stolen, prevent Affirm from incurring financial loss, and increase the trust that consumers and partners have in the Affirm ecosystem\",\n",
       "  'Partner with the ML platform team to build fraud specific ML infrastructure',\n",
       "  'Research ground breaking solutions and develop prototypes that drive the future of fraud decisioning at Affirm',\n",
       "  'Implement and scale data pipelines, new features, and algorithms that are essential to our production models',\n",
       "  'Collaborate with the engineering, fraud, and product teams to define requirements for new products',\n",
       "  'Develop fraud models to maximize user conversion while minimizing fraud losses and data costs'],\n",
       " 'qualification_degree': 'Bachelors',\n",
       " 'qualification_preferred_degree': 'PhD',\n",
       " 'qualification_years_of_experience': '5+',\n",
       " 'qualification_tech_stack_experience': ['Python',\n",
       "  'Spark',\n",
       "  'Ray',\n",
       "  'scikit-learn',\n",
       "  'pandas',\n",
       "  'numpy',\n",
       "  'xgboost',\n",
       "  'pytorch'],\n",
       " 'qualification_domain_knowledge': 'fraud risk',\n",
       " 'qualification_leading_experience': ['Excellent written and oral communication skills',\n",
       "  'the capability to drive cross-functional requirements with product and engineering teams',\n",
       "  'The ability to present technical concepts and results in an audience-appropriate way'],\n",
       " 'qualification_research_experience': ['Research ground breaking solutions and develop prototypes that drive the future of fraud decisioning at Affirm']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.text.strip('```').strip('json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
